{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Reconstruct target file with source collection frames\n",
    "\n",
    "This is the final notebook of the Freesound AMPLAB session and contains the code that performs *audio mosaicing* to construct a new version of the target file by using audio frames chosen from the source collection. This notebook used the DataFrames generated in the previous notebooks which contain metadata about the Freesound sounds in the source collection, the analysis results of the source collection and the analysis results of the target audio file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import essentia\n",
    "import essentia.standard as estd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from IPython.display import display, Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all DataFrames created in the previous notebooks\n",
    "DATASET_FILENAME = 'dataframe.csv'\n",
    "DATAFRAME_SOURCE_UNITS_FILENAME = 'dataframe_source_units.csv'\n",
    "DATAFRAME_TARGET_FILE_FILENAME = 'dataframe_target.csv'\n",
    "\n",
    "df = pd.read_csv(open(DATASET_FILENAME), index_col=0)\n",
    "df_source_units = pd.read_csv(open(DATAFRAME_SOURCE_UNITS_FILENAME), index_col=0)\n",
    "df_target = pd.read_csv(open(DATAFRAME_TARGET_FILE_FILENAME), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some util functions\n",
    "# NOTE: remember that if you update these util functions and want to do a new audio mosaicing, you'll need \n",
    "# to re-run both this cell (to update the util functions) and the cell below (which uses the util functions to\n",
    "# do the audio mosaicing).\n",
    "\n",
    "loaded_audio_files = {}\n",
    "\n",
    "def get_audio_file_segment(file_path, start_sample, n_samples):\n",
    "    \"\"\"Load audio file. Try to get it from memory first. If not there, open it and save in memory for next time.\n",
    "    \"\"\"\n",
    "    if file_path not in loaded_audio_files:\n",
    "        loader = estd.MonoLoader(filename=file_path)\n",
    "        audio = loader()\n",
    "        loaded_audio_files[file_path] = audio\n",
    "    else:\n",
    "        audio = loaded_audio_files[file_path]\n",
    "        \n",
    "    # Return segment\n",
    "    return audio[start_sample:start_sample + n_samples]\n",
    "\n",
    "def find_similar_frames(query_frame, source_data_frame, n, features):\n",
    "    \"\"\"Find the 'n' mosr similar frames for a given 'query_frame' from those in the given 'source_data_frame'.\n",
    "    Similarity is computed using a nearest neighbours algorithm and taking only into account the feature list\n",
    "    given in the 'features' parameter.\n",
    "    \"\"\"\n",
    "    query_frame = query_frame.reshape(1,-1)\n",
    "    nbrs = NearestNeighbors(n_neighbors=n, algorithm='ball_tree').fit(source_data_frame[features].values)\n",
    "    distances, indices = nbrs.kneighbors(query_frame)\n",
    "    return [source_data_frame.iloc[k] for k in indices[0]]\n",
    "\n",
    "def chose_frame_from_source_collection(target_frame, source_data_frame):\n",
    "    \"\"\"Choose one frame from the source collection to replace the target frame.\n",
    "    This implementation chooses the source frame usinng a similarity algorithm 'find_similar_frames',\n",
    "    and a specific set of similarity features for timbre (MFCC).\n",
    "    You can modify this function to implement new ways to choose a frame from the source.\n",
    "    \"\"\"\n",
    "    n_neighbours_to_find = 10\n",
    "    similarity_features = ['mfcc_0', 'mfcc_1', 'mfcc_2', 'mfcc_3', 'mfcc_4', 'mfcc_5', 'mfcc_6', 'mfcc_7', 'mfcc_8', 'mfcc_9', 'mfcc_10', 'mfcc_11', 'mfcc_12']  # Use MFCCs for sound similarity ['mfcc_0', 'mfcc_1']\n",
    "\n",
    "    # Find the 10 most similar frames to the target_frame from df_source_units \n",
    "    query_frame = target_frame[similarity_features].values\n",
    "    similar_frames = find_similar_frames(query_frame, source_data_frame, n_neighbours_to_find, similarity_features)\n",
    "    \n",
    "    # Choose the first one as is the most similar\n",
    "    most_similar_frame = similar_frames[0]\n",
    "    \n",
    "    return most_similar_frame\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Do the reconstruction (audio mosaicing) of the target file using audio chunks (units, frames) from the sounds in the source collection\n",
    "\n",
    "# Load target audio file to get its total length and to use it later\n",
    "target_sound_filename = df_target.iloc[0]['path']\n",
    "target_audio = estd.MonoLoader(filename=target_sound_filename)()\n",
    "total_length_target_audio = len(target_audio)\n",
    "\n",
    "# Init array where to put the audio of the reconstructed file\n",
    "generated_audio = np.zeros(total_length_target_audio)\n",
    "\n",
    "# Init list where to store IDs of sounds used in the reconstruction\n",
    "selected_freesound_ids = []\n",
    "\n",
    "# Iterate over the analyzed frame of the target file\n",
    "print('Reconstructing audio file...')\n",
    "for i in range(0, len(df_target)):\n",
    "    target_frame = df_target.iloc[i]  # Get current frame\n",
    "    \n",
    "    # Choose one frame from the source collection to replace the target frame\n",
    "    most_similar_frame = chose_frame_from_source_collection(target_frame, df_source_units)\n",
    "    \n",
    "    # Store freesound ID of the original sound where the 'most_similar_frame' belongs to\n",
    "    selected_freesound_ids.append(most_similar_frame['freesound_id'])\n",
    "    \n",
    "    # Get the audio segment corresponding to the 'most_similar_frame'\n",
    "    target_frame_n_samples = target_frame['end_sample'] - target_frame['start_sample']\n",
    "    most_similar_frame_audio = get_audio_file_segment(most_similar_frame['path'], most_similar_frame['start_sample'], target_frame_n_samples)\n",
    "    \n",
    "    # Add audio segment to the reconstructed audio array\n",
    "    generated_audio[target_frame['start_sample']:target_frame['start_sample']+len(most_similar_frame_audio)] = most_similar_frame_audio\n",
    "\n",
    "# Store the results in a WAV file\n",
    "generated_audio_filename = '{0}.reconstructed.wav'.format(target_sound_filename)\n",
    "estd.MonoWriter(filename=generated_audio_filename, format='wav', sampleRate=44100)(essentia.array(generated_audio))\n",
    "print('Audio generated and saved in {0}!\\nIt contains audio from the following sounds:'.format(generated_audio_filename))\n",
    "display(df.loc[df['freesound_id'].isin(selected_freesound_ids)])  # Show metadata for the Freesound sounds used in the reconstruction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show further results of the reconstruction\n",
    "\n",
    "# Plot waveforms\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(target_audio)\n",
    "plt.axis([0, len(target_audio), -1, 1])\n",
    "plt.title('Target audio')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(generated_audio)\n",
    "plt.axis([0, len(target_audio), -1, 1])\n",
    "plt.title('Reconstructed')\n",
    "plt.show()\n",
    "\n",
    "# Show audio players\n",
    "print('Target audio')\n",
    "display(Audio(target_audio, rate=44100))\n",
    "\n",
    "print('Reconstructed')\n",
    "display(Audio(generated_audio, rate=44100))\n",
    "\n",
    "print('Mix of both signals')\n",
    "display(Audio(generated_audio * 0.5 + target_audio * 0.5, rate=44100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
